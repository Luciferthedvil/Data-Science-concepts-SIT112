{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task P5** (Due April 24, 11 AM)\n",
    "## Cleaning the Avocado Data\n",
    "\n",
    "##### This task uses the avocado dataset. The dataset contains historical data on avocado prices and sales volume in multiple U.S. markets. One of the columns in this dataset, Unnamed: 0, contains sequential numbers that are irrelevant to analyzing this data. Three of the other columns contain sales for PLU (price look-up) codes 4046, 4225, and 4770. These columns will not be used in this task. If you review the data, you’ll see that some of the regions overlap. For example, one of the regions is the entire U.S., and all of the other regions are parts of the U.S. Because of that, you would need to review this data carefully before determining the best way to analyze it. For the purposes of this task though, the overlapping regions won’t be taken into consideration.\n",
    "\n",
    "##### https://www.kaggle.com/neuromusic/avocado-prices\n",
    "\n",
    "<img src=\"avocado-logo.png\" alt=\"SIT112 Avocado!\" width=\"1800\" height=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Instructions\n",
    "\n",
    "1. Complete this task without looking at the solution provided to you. \n",
    "2. You can then look at the solution provided to you and compare it against yours.\n",
    "3. Complete and submit the TaskCompletionReport in PDF format using Ontrack. You can do this by the end of Week 12, but feedback will only be provided for submissions received by 11 AM on the due date.   \n",
    "4. Do **not** include the solution (yours or the one provided to you) in your submission.\n",
    "5. The workshops are the primary venue for you to seek help if you need any clarification/assistance. The tutors are there to help you complete and submit the tasks. Please avoid emailing your code or screenshots to the tutors outside workshop hours. \n",
    "6. Consider using online resources such as ChatGPT to strengthen your understanding of the task. \n",
    "\n",
    "Good luck :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### B. Write Python code that performs (answers) the following operations (questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.\tRead the data from the CSV file into a DataFrame and display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "data = pd.read_csv('avocado.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.\tUse the info() function to check if any of the columns have missing values. Explain how this cane be achieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "data.info(verbose=True, memory_usage='deep', show_counts=True)\n",
    "# there are no missing values in the any columns. We can come to know about this by looking at the RangeIndex and the non-null count.\n",
    "# the RangeIndex is showing 18249 entries in total and the Non-Null count for all the columns are also 18249, which shows that there are no missing values in any columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Is there any other way we can check the missing values in the columns - without using info()? Write Python code for this. Hint: use isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values\n",
      "Unnamed: 0      0\n",
      "Date            0\n",
      "AveragePrice    0\n",
      "Total Volume    0\n",
      "4046            0\n",
      "4225            0\n",
      "4770            0\n",
      "Total Bags      0\n",
      "Small Bags      0\n",
      "Large Bags      0\n",
      "XLarge Bags     0\n",
      "type            0\n",
      "year            0\n",
      "region          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# you can ask ChatGPT :)\n",
    "missing_values = data.isna().sum()\n",
    "print(\"The number of missing values\")\n",
    "print(missing_values)\n",
    "\n",
    "# using isna() to find whether there are any missing values in each column. It returns true if any corresponding element in the dataframe is NaN (missing) and takes a count of the missing value, and returns false otherwise.\n",
    "# using sum() we can find the total number of missing values in each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.\tDisplay the unique values in the region column, and notice that one of the regions is TotalUS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albany', 'Atlanta', 'BaltimoreWashington', 'Boise', 'Boston',\n",
       "       'BuffaloRochester', 'California', 'Charlotte', 'Chicago',\n",
       "       'CincinnatiDayton', 'Columbus', 'DallasFtWorth', 'Denver',\n",
       "       'Detroit', 'GrandRapids', 'GreatLakes', 'HarrisburgScranton',\n",
       "       'HartfordSpringfield', 'Houston', 'Indianapolis', 'Jacksonville',\n",
       "       'LasVegas', 'LosAngeles', 'Louisville', 'MiamiFtLauderdale',\n",
       "       'Midsouth', 'Nashville', 'NewOrleansMobile', 'NewYork',\n",
       "       'Northeast', 'NorthernNewEngland', 'Orlando', 'Philadelphia',\n",
       "       'PhoenixTucson', 'Pittsburgh', 'Plains', 'Portland',\n",
       "       'RaleighGreensboro', 'RichmondNorfolk', 'Roanoke', 'Sacramento',\n",
       "       'SanDiego', 'SanFrancisco', 'Seattle', 'SouthCarolina',\n",
       "       'SouthCentral', 'Southeast', 'Spokane', 'StLouis', 'Syracuse',\n",
       "       'Tampa', 'TotalUS', 'West', 'WestTexNewMexico'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "data['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.\tDrop rows that have a region of TotalUS, and then check to see how many rows were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping:  18249\n",
      "Number of rows after dropping:  17911\n",
      "Number of rows dropped:  338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Albany', 'Atlanta', 'BaltimoreWashington', 'Boise', 'Boston',\n",
       "       'BuffaloRochester', 'California', 'Charlotte', 'Chicago',\n",
       "       'CincinnatiDayton', 'Columbus', 'DallasFtWorth', 'Denver',\n",
       "       'Detroit', 'GrandRapids', 'GreatLakes', 'HarrisburgScranton',\n",
       "       'HartfordSpringfield', 'Houston', 'Indianapolis', 'Jacksonville',\n",
       "       'LasVegas', 'LosAngeles', 'Louisville', 'MiamiFtLauderdale',\n",
       "       'Midsouth', 'Nashville', 'NewOrleansMobile', 'NewYork',\n",
       "       'Northeast', 'NorthernNewEngland', 'Orlando', 'Philadelphia',\n",
       "       'PhoenixTucson', 'Pittsburgh', 'Plains', 'Portland',\n",
       "       'RaleighGreensboro', 'RichmondNorfolk', 'Roanoke', 'Sacramento',\n",
       "       'SanDiego', 'SanFrancisco', 'Seattle', 'SouthCarolina',\n",
       "       'SouthCentral', 'Southeast', 'Spokane', 'StLouis', 'Syracuse',\n",
       "       'Tampa', 'West', 'WestTexNewMexico'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('avocado.csv')\n",
    "print(\"Number of rows before dropping: \",len(data))\n",
    "\n",
    "data1 = data.query('region != \"TotalUS\"')\n",
    "data1 = data[data.region != 'TotalUS']\n",
    "\n",
    "print(\"Number of rows after dropping: \",len(data1))\n",
    "\n",
    "dropped_rows = len(data) - len(data1)\n",
    "\n",
    "print(\"Number of rows dropped: \",dropped_rows )\n",
    "\n",
    "data1['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.\tDrop the Unnamed: 0, 4046, 4225, and 4770 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0', '4225', '4770'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# write your code here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data1\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4225\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4770\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m data1\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4046\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0', '4225', '4770'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "data1.drop(columns=['Unnamed: 0','4225','4770'], errors='raise', inplace=True)\n",
    "data1.drop(columns=['4046'], errors='raise', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              169\n",
       "AveragePrice      259\n",
       "Total Volume    17899\n",
       "Total Bags      17759\n",
       "Small Bags      16983\n",
       "Large Bags      14744\n",
       "XLarge Bags      5417\n",
       "type                2\n",
       "year                4\n",
       "region             53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.nunique()\n",
    "# This says that the columns specified on top are dropped. That is why it is not visible when the data1.nunique() is run, we are\n",
    "# not able to see those dropped columns.\n",
    "\n",
    "# This error \"['Unnamed: 0', '4225', '4770'] not found in axis\" is shown because i tried to run the code again after the columns \n",
    "# were successfully removed. that is why it says that the columns are not found because they are already removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.\tConvert the Date column to the DateTime type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date before conversion\n",
      "Data type:  object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2015-12-27\n",
       "1   2015-12-20\n",
       "2   2015-12-13\n",
       "3   2015-12-06\n",
       "4   2015-11-29\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date after conversion\n",
      "Data type:  datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2015-12-27\n",
       "1   2015-12-20\n",
       "2   2015-12-13\n",
       "3   2015-12-06\n",
       "4   2015-11-29\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(data1)\n",
    "print(\"Date before conversion\")\n",
    "date_column = df['Date']\n",
    "print(\"Data type: \",df['Date'].dtypes)\n",
    "\n",
    "display(date_data.head(5))\n",
    "\n",
    "df2 = pd.DataFrame(data1)\n",
    "print(\"Date after conversion\")\n",
    "df2['Date'] = df2['Date'].apply(pd.to_datetime)\n",
    "print(\"Data type: \",df2['Date'].dtypes)\n",
    "\n",
    "display(date_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.\tCheck that these changes have been applied to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17911 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume  Total Bags  Small Bags  \\\n",
       "0     2015-12-27          1.33      64236.62     8696.87     8603.62   \n",
       "1     2015-12-20          1.35      54876.98     9505.56     9408.07   \n",
       "2     2015-12-13          0.93     118220.22     8145.35     8042.21   \n",
       "3     2015-12-06          1.08      78992.15     5811.16     5677.40   \n",
       "4     2015-11-29          1.28      51039.60     6183.95     5986.26   \n",
       "...          ...           ...           ...         ...         ...   \n",
       "18244 2018-02-04          1.63      17074.83    13498.67    13066.82   \n",
       "18245 2018-01-28          1.71      13888.04     9264.84     8940.04   \n",
       "18246 2018-01-21          1.87      13766.76     9394.11     9351.80   \n",
       "18247 2018-01-14          1.93      16205.22    10969.54    10919.54   \n",
       "18248 2018-01-07          1.62      17489.58    12014.15    11988.14   \n",
       "\n",
       "       Large Bags  XLarge Bags          type  year            region  \n",
       "0           93.25          0.0  conventional  2015            Albany  \n",
       "1           97.49          0.0  conventional  2015            Albany  \n",
       "2          103.14          0.0  conventional  2015            Albany  \n",
       "3          133.76          0.0  conventional  2015            Albany  \n",
       "4          197.69          0.0  conventional  2015            Albany  \n",
       "...           ...          ...           ...   ...               ...  \n",
       "18244      431.85          0.0       organic  2018  WestTexNewMexico  \n",
       "18245      324.80          0.0       organic  2018  WestTexNewMexico  \n",
       "18246       42.31          0.0       organic  2018  WestTexNewMexico  \n",
       "18247       50.00          0.0       organic  2018  WestTexNewMexico  \n",
       "18248       26.01          0.0       organic  2018  WestTexNewMexico  \n",
       "\n",
       "[17911 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17911 entries, 0 to 18248\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          17911 non-null  datetime64[ns]\n",
      " 1   AveragePrice  17911 non-null  float64       \n",
      " 2   Total Volume  17911 non-null  float64       \n",
      " 3   Total Bags    17911 non-null  float64       \n",
      " 4   Small Bags    17911 non-null  float64       \n",
      " 5   Large Bags    17911 non-null  float64       \n",
      " 6   XLarge Bags   17911 non-null  float64       \n",
      " 7   type          17911 non-null  object        \n",
      " 8   year          17911 non-null  int64         \n",
      " 9   region        17911 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()\n",
    "#now the Date column's datatype has changed to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
